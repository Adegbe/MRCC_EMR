import streamlit as st
import pandas as pd
from data_cleaner import DataCleaner  # Assuming your script is named data_cleaner.py

st.set_page_config(page_title="MRCC EMR Preprocessing Tool", layout="centered")

st.title("MRCC EMR Preprocessing Tool")
st.markdown("**This tool is designed for internal use only. Ensure all data handling complies with privacy regulations.**")

st.markdown("---")

uploaded_file = st.file_uploader("Upload your EMR file (CSV, Excel, or JSON)", type=["csv", "xls", "xlsx", "json"])

with st.expander("Preprocessing Options", expanded=True):
    normalize_colnames = st.checkbox("Normalize Column Names", value=True)
    standardize_gender = st.checkbox("Standardize Gender Field", value=True)
    handle_missing = st.checkbox("Handle Missing Values", value=True)
    remove_duplicates = st.checkbox("Detect and Remove Duplicates", value=True)
    mask_pii = st.checkbox("Mask PII (Personally Identifiable Information)", value=True)
    correct_invalid = st.checkbox("Correct Invalid Entries", value=True)
    validate_types = st.checkbox("Validate Data Types", value=True)

    pii_columns = st.text_input("Specify PII columns to mask (comma separated)", value="name,email,phone")
    duplicate_keys = st.text_input("Specify columns to detect duplicates (comma separated)", value="id")

if uploaded_file is not None:
    cleaner = DataCleaner()

    try:
        df = cleaner.load_file(uploaded_file)
        cleaner.set_pii_columns([col.strip() for col in pii_columns.split(",")])
        cleaner.set_duplicate_key_columns([col.strip() for col in duplicate_keys.split(",")])

        if normalize_colnames:
            df = cleaner._normalize_column_names(df)
        if standardize_gender or handle_missing or correct_invalid or validate_types:
            cleaner.validated_columns = cleaner._get_validated_columns(df)
        if standardize_gender:
            df = cleaner._clean_string_data(df)
        if handle_missing:
            df = cleaner._handle_missing_data(df)
        if correct_invalid or validate_types:
            df = cleaner._correct_wrong_entries(df)
        if remove_duplicates:
            df = cleaner._handle_duplicates(df)
        if mask_pii:
            df = cleaner._mask_pii(df)

        st.success("‚úÖ Preprocessing complete.")
        st.dataframe(df.head())

        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button(
            "üì• Download Cleaned CSV",
            csv,
            "cleaned_data.csv",
            "text/csv",
            key="download-csv"
        )

    except Exception as e:
        st.error(f"‚ö†Ô∏è Error during processing: {str(e)}")
